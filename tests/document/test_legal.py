"""
Legal Document Module Tests
==========================

Comprehensive test suite for legal document AI capabilities.
Tests contract analysis, compliance checking, and legal document processing.
"""

import pytest
import asyncio
from unittest.mock import AsyncMock, Mock, patch
from datetime import datetime
from pathlib import Path

from src.vega.document.legal import LegalDocumentAI, ContractAnalyzer, ComplianceChecker
from src.vega.document.base import ProcessingContext, ProcessingResult
from tests.document.fixtures import (
    sample_legal_documents,
    mock_legal_processor,
    create_test_context,
    performance_monitor,
)


class TestLegalDocumentAI:
    """Test suite for LegalDocumentAI class"""

    @pytest.fixture
    async def legal_ai(self):
        """Create and initialize legal AI instance"""
        ai = LegalDocumentAI()
        await ai.initialize()
        return ai

    @pytest.fixture
    def legal_context(self):
        """Create legal document processing context"""
        return create_test_context(
            content=sample_legal_documents["nda"],
            document_type="legal",
            processing_mode="analysis",
            metadata={"document_category": "contract"},
        )

    @pytest.mark.asyncio
    async def test_initialization(self):
        """Test legal AI initialization"""
        ai = LegalDocumentAI()

        # Should not be initialized yet
        assert not ai.is_initialized

        # Initialize
        await ai.initialize()

        # Should be initialized now
        assert ai.is_initialized
        assert ai.contract_analyzer is not None
        assert ai.compliance_checker is not None

    @pytest.mark.asyncio
    async def test_process_document_basic(self, legal_ai, legal_context):
        """Test basic legal document processing"""
        result = await legal_ai.process_document(legal_context)

        assert isinstance(result, ProcessingResult)
        assert result.session_id == legal_context.session_id
        assert result.success is True
        assert "legal_analysis" in result.results
        assert result.processing_time_ms > 0

    @pytest.mark.asyncio
    async def test_contract_analysis(self, legal_ai):
        """Test contract analysis capabilities"""
        context = create_test_context(
            content=sample_legal_documents["service_agreement"],
            processing_mode="contract_analysis",
            metadata={"contract_type": "service_agreement"},
        )

        result = await legal_ai.process_document(context)

        contract_analysis = result.results.get("contract_analysis", {})

        # Check analysis components
        assert "key_terms" in contract_analysis
        assert "obligations" in contract_analysis
        assert "risk_factors" in contract_analysis
        assert "compliance_issues" in contract_analysis

        # Validate key terms structure
        key_terms = contract_analysis["key_terms"]
        assert isinstance(key_terms, list)

        for term in key_terms:
            assert "term" in term
            assert "description" in term
            assert "importance" in term

    @pytest.mark.asyncio
    async def test_compliance_checking(self, legal_ai):
        """Test compliance checking features"""
        context = create_test_context(
            content=sample_legal_documents["privacy_policy"],
            processing_mode="compliance",
            metadata={"regulation": "GDPR"},
        )

        result = await legal_ai.process_document(context)

        compliance = result.results.get("compliance", {})

        assert "compliance_status" in compliance
        assert "violations" in compliance
        assert "recommendations" in compliance
        assert "risk_level" in compliance

    @pytest.mark.asyncio
    async def test_legal_risk_assessment(self, legal_ai):
        """Test legal risk assessment"""
        context = create_test_context(
            content=sample_legal_documents["liability_clause"],
            processing_mode="risk_assessment",
            metadata={"assessment_type": "liability"},
        )

        result = await legal_ai.process_document(context)

        risk_assessment = result.results.get("risk_assessment", {})

        assert "overall_risk" in risk_assessment
        assert "risk_factors" in risk_assessment
        assert "mitigation_strategies" in risk_assessment
        assert "recommendation" in risk_assessment

    @pytest.mark.asyncio
    async def test_clause_extraction(self, legal_ai):
        """Test legal clause extraction"""
        context = create_test_context(
            content=sample_legal_documents["complex_contract"],
            processing_mode="clause_extraction",
        )

        result = await legal_ai.process_document(context)

        clauses = result.results.get("clauses", [])

        assert isinstance(clauses, list)
        assert len(clauses) > 0

        for clause in clauses:
            assert "type" in clause
            assert "content" in clause
            assert "significance" in clause

    @pytest.mark.asyncio
    async def test_legal_entity_recognition(self, legal_ai):
        """Test legal entity and date recognition"""
        context = create_test_context(
            content=sample_legal_documents["entity_heavy_contract"],
            processing_mode="entity_recognition",
        )

        result = await legal_ai.process_document(context)

        entities = result.results.get("entities", {})

        assert "parties" in entities
        assert "dates" in entities
        assert "monetary_amounts" in entities
        assert "locations" in entities

    @pytest.mark.asyncio
    async def test_contract_comparison(self, legal_ai):
        """Test contract comparison functionality"""
        # This would require two documents
        context = create_test_context(
            content=sample_legal_documents["nda"],
            processing_mode="comparison",
            metadata={
                "comparison_document": sample_legal_documents["service_agreement"],
                "comparison_type": "clause_differences",
            },
        )

        result = await legal_ai.process_document(context)

        comparison = result.results.get("comparison", {})

        assert "differences" in comparison
        assert "similarities" in comparison
        assert "recommendations" in comparison

    @pytest.mark.asyncio
    async def test_legal_document_drafting_assistance(self, legal_ai):
        """Test legal document drafting assistance"""
        context = create_test_context(
            content="Draft a non-disclosure agreement for software development project",
            processing_mode="drafting_assistance",
            metadata={"document_type": "nda", "project_type": "software"},
        )

        result = await legal_ai.process_document(context)

        draft = result.results.get("draft_assistance", {})

        assert "suggested_clauses" in draft
        assert "template_recommendations" in draft
        assert "risk_considerations" in draft

    @pytest.mark.asyncio
    async def test_error_handling(self, legal_ai):
        """Test error handling in legal processing"""
        # Test with empty content
        context = create_test_context(content="", processing_mode="analysis")

        result = await legal_ai.process_document(context)

        assert result.success is False
        assert "error" in result.results
        assert "Empty content" in result.results["error"]

    @pytest.mark.asyncio
    async def test_unsupported_language(self, legal_ai):
        """Test handling of non-English legal documents"""
        context = create_test_context(
            content="Contrato de servicios en espa√±ol...",
            processing_mode="analysis",
            metadata={"language": "spanish"},
        )

        result = await legal_ai.process_document(context)

        # Should handle gracefully with language warning
        assert "language_warning" in result.metadata
        assert "detected_language" in result.metadata

    @pytest.mark.asyncio
    async def test_large_contract_processing(self, legal_ai):
        """Test processing of large legal documents"""
        large_content = sample_legal_documents["complex_contract"] * 50

        context = create_test_context(content=large_content, processing_mode="analysis")

        with performance_monitor() as monitor:
            result = await legal_ai.process_document(context)

        assert result.success is True
        assert monitor.memory_usage < 200  # MB
        assert monitor.processing_time < 60  # seconds

    @pytest.mark.asyncio
    async def test_concurrent_legal_processing(self, legal_ai):
        """Test concurrent legal document processing"""
        contexts = [
            create_test_context(
                content=doc, processing_mode="analysis", session_id=f"legal_session_{i}"
            )
            for i, doc in enumerate(sample_legal_documents.values())
        ]

        # Process multiple documents concurrently
        tasks = [legal_ai.process_document(ctx) for ctx in contexts]
        results = await asyncio.gather(*tasks)

        # All should succeed
        assert all(result.success for result in results)

        # Session IDs should be preserved
        for i, result in enumerate(results):
            assert result.session_id == f"legal_session_{i}"

    @pytest.mark.asyncio
    async def test_health_check(self, legal_ai):
        """Test legal AI health check"""
        health = await legal_ai.health_check()

        assert isinstance(health, dict)
        assert "healthy" in health
        assert "ready" in health
        assert health["healthy"] is True
        assert health["ready"] is True
        assert "components" in health

    @pytest.mark.asyncio
    async def test_cleanup(self, legal_ai):
        """Test cleanup functionality"""
        # Verify initial state
        assert legal_ai.is_initialized is True

        # Cleanup
        await legal_ai.cleanup()

        # Verify cleanup
        assert legal_ai.is_initialized is False


class TestContractAnalyzer:
    """Test suite for ContractAnalyzer component"""

    @pytest.fixture
    def contract_analyzer(self):
        """Create contract analyzer instance"""
        return ContractAnalyzer()

    @pytest.mark.asyncio
    async def test_contract_analyzer_initialization(self, contract_analyzer):
        """Test contract analyzer initialization"""
        await contract_analyzer.initialize()
        assert contract_analyzer.is_initialized is True

    @pytest.mark.asyncio
    async def test_key_terms_extraction(self, contract_analyzer):
        """Test key terms extraction from contracts"""
        await contract_analyzer.initialize()

        context = create_test_context(
            content=sample_legal_documents["service_agreement"],
            metadata={"extract": "key_terms"},
        )

        result = await contract_analyzer.analyze_contract(context)

        assert "key_terms" in result
        assert isinstance(result["key_terms"], list)

    @pytest.mark.asyncio
    async def test_obligation_identification(self, contract_analyzer):
        """Test obligation identification in contracts"""
        await contract_analyzer.initialize()

        context = create_test_context(
            content=sample_legal_documents["nda"], metadata={"analyze": "obligations"}
        )

        result = await contract_analyzer.analyze_contract(context)

        assert "obligations" in result
        obligations = result["obligations"]

        assert "party_a_obligations" in obligations
        assert "party_b_obligations" in obligations
        assert "mutual_obligations" in obligations


class TestComplianceChecker:
    """Test suite for ComplianceChecker component"""

    @pytest.fixture
    def compliance_checker(self):
        """Create compliance checker instance"""
        return ComplianceChecker()

    @pytest.mark.asyncio
    async def test_compliance_checker_initialization(self, compliance_checker):
        """Test compliance checker initialization"""
        await compliance_checker.initialize()
        assert compliance_checker.is_initialized is True

    @pytest.mark.asyncio
    async def test_gdpr_compliance_check(self, compliance_checker):
        """Test GDPR compliance checking"""
        await compliance_checker.initialize()

        context = create_test_context(
            content=sample_legal_documents["privacy_policy"],
            metadata={"regulation": "GDPR"},
        )

        result = await compliance_checker.check_compliance(context)

        assert "gdpr_compliance" in result
        gdpr = result["gdpr_compliance"]

        assert "status" in gdpr
        assert "missing_requirements" in gdpr
        assert "recommendations" in gdpr

    @pytest.mark.asyncio
    async def test_sox_compliance_check(self, compliance_checker):
        """Test SOX compliance checking"""
        await compliance_checker.initialize()

        context = create_test_context(
            content=sample_legal_documents["financial_agreement"],
            metadata={"regulation": "SOX"},
        )

        result = await compliance_checker.check_compliance(context)

        assert "sox_compliance" in result
        sox = result["sox_compliance"]

        assert "financial_controls" in sox
        assert "reporting_requirements" in sox
        assert "compliance_gaps" in sox

    @pytest.mark.asyncio
    async def test_multi_regulation_check(self, compliance_checker):
        """Test checking against multiple regulations"""
        await compliance_checker.initialize()

        context = create_test_context(
            content=sample_legal_documents["comprehensive_policy"],
            metadata={"regulations": ["GDPR", "HIPAA", "SOX"]},
        )

        result = await compliance_checker.check_compliance(context)

        # Should have results for all requested regulations
        assert "gdpr_compliance" in result
        assert "hipaa_compliance" in result
        assert "sox_compliance" in result
